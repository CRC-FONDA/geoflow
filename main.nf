nextflow.enable.dsl = 2

include { build_vrt_stack; explode_base_files; spat_lucas } from './preprocessNF/preprocessing_workflows.nf'
include { mask_layer_stack } from './preprocessNF/mask.nf'
include { calculate_spectral_indices } from './preprocessNF/indices.nf'
include { calc_stms_pr as stms_ls; calc_stms_pr as stms_sen } from './stmsNF/stms.nf'
include { extract_features } from './hl/feature_extraction.nf'

/* NOTE: This expects a cubed data provided or 'managed' by FORCE as input
 * - Flatten (partially) nested return from `Channel.fromFilePairs`
 * - Extract various information from the file path and file name, such as:
 *   - tile ID (generated by FORCE)
 *   - observation date
 *   - sensor name (long)
 *   - single letter sensor abbreviation
 *   - scene ID (i.e. file name of the input file, minus the prodcut 'id'
 *     (such as 'BOA') and file type
 */
def prepare_channel = input -> {
	String reflectance_path = input[1][0]
	String quality_path = input[1][0]
	String tile = reflectance_path.split('/')[-2]
        String date = scene.split('_')[0]
	String scene = input[0]
	String sensor = scene.split('_')[-1]
	String sensor_abbreviation = sensor[0]

	return [tile, date, scene, sensor, sensor_abbreviation, reflectance_path, quality_path]
}

workflow {
    Channel
	.fromPath([params.lucas_survey, params.lucas_geom], type: 'file')
	.concat(Channel.of(params.lucas_query, params.lucas_epsg))
	.collect()
	.set( { lucas } )

    spat_lucas(lucas)

    Channel
	.of(params.spectral_indices_mapping)
	.set( { spectral_indices } )

    Channel
	.of(params.calculate_stms)
	.set( { stm_choices } )

    Channel
	.of(params.stm_band_mapping_sentinel)
	.mix( spectral_indices )
	.flatMap()
	.combine( stm_choices )
	.set( { stm_combination_sentinel } )

    Channel
	.of(params.stm_band_mapping_landsat)
	.mix( spectral_indices )
	.flatMap()
	.combine( stm_choices )
	.set( { stm_combination_landsat } )

    // TODO: remove subset
    Channel
        .fromFilePairs(params.input_cube)
	.map( { prepare_channel } )
        .filter( { it[1] >= params.processing_timeframe["START"] && it[1] <= params.processing_timeframe["END"] } )
	.take(15)
        .set( { ch_dataP } )

    mask_layer_stack(ch_dataP)

    mask_layer_stack
        .out
        .tap( { ch_base_files } )
        .set( { ch_for_indices } )

    calculate_spectral_indices(
	ch_for_indices
		.combine(
			spectral_indices
			.flatMap()
		)
    )

    explode_base_files(ch_base_files)

    // The group size should be set, so that a "package"/"bundle" can be released as soon as everything needed is processed and not
    // we don't have to wait until everything is processed. In theory, there is a function for doing so (grouKey, see https://github.com/nextflow-io/nextflow/issues/796#issuecomment-407108667),
    // but this doesn't work here. Fabian might come up with a solution. Until then, this issue is postponed.
    Channel
        .empty()
	.mix(calculate_spectral_indices.out, explode_base_files.out)
      //  .mix(calc_indices.out, explode_base_files.out)
	// regardless of sensor type, the group size is (as long as all indices can be calculated for all platforms) always N-indices + 1 because explode_base_files returns nested lists
	// as soon as this is not the case anymore, the approach implemented by Fabian in his git pull request would be needed.
        .groupTuple(by: [0, 1], size: 8)
        // [Tile ID, Scene ID, Sensor type, [BOA, exploded bands and indices]]
        .map( { [it[0], it[1], it[2][0], [it[3][0], it[4].flatten()].flatten()] } )
        .set( { ch_grouped_bands } )

    build_vrt_stack(ch_grouped_bands)

    /*
    *   conceptually, new chunk as per proposed flow chart
    */

    // Rest siehe Notizen!
    Channel
	.of(params.stm_timeframes.flatten())
	.set( { stm_timeframes } )

    // TODO indicate (via filename??) what the grouping variable is/was -> this also needs to be communicated via NF channels
    build_vrt_stack
    .out
    .map( { get_year_month_etc(it) } )
    .map( { get_short_sensor(it) } )
    .tap( { ch_stacked_raster } ) // likely needed later on because stms discard sensor/scene specific stack
    .map( { it[0..<-1] } ) // drop vrt stack for next step (calculating stms); I couldn't figure out if it's possible to pass an array to a NF process marked as path -> I don't think so TODO
    .groupTuple(by: [0, 2, 5]) // group by TID, Landsat/Sentinel and month
    .map( { [it[0], it[1], it[2], it[3], it[4], it[5], it[6], it[7].flatten()] } )
    .branch ( {
	sentinel: it[2] == 'S'
	landsat: it[2] == 'L'
    	} )
    .set( { ch_group_stacked_raster } )

    stms_ls(
	ch_group_stacked_raster
		.landsat
		.combine(stm_combination_landsat)
    )

//    stms_sen(
//	ch_group_stacked_raster
//		.sentinel
//		.combine(stm_combination_sentinel)
//    )

    create_classification_dataset(stms_ls.out)

    merge_classification_datasets(create_classification.out.collect())

    train_rf_classifier(merge_classification_datasets.out)

    predict_classifier(train_rf_classifier.out)
}

